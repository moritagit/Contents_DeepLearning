\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{junsrt}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}はじめに}{2}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Perceptron}{2}{section.2}}
\newlabel{sec:perceptron}{{2}{2}{Perceptron}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces パーセプトロンの図\relax }}{2}{figure.1}}
\newlabel{fig:perceptron}{{1}{2}{パーセプトロンの図\relax }{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Neural Network}{3}{section.3}}
\newlabel{sec:neural_network}{{3}{3}{Neural Network}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces ニューラルネットワークの図\relax }}{3}{figure.2}}
\newlabel{fig:neural_network}{{2}{3}{ニューラルネットワークの図\relax }{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}活性化関数}{4}{section.4}}
\newlabel{sec:activate_function}{{4}{4}{活性化関数}{section.4}{}}
\newlabel{fig:step_function}{{3a}{5}{ステップ関数\relax }{subfigure.3.1}{}}
\newlabel{sub@fig:step_function}{{a}{5}{ステップ関数\relax }{subfigure.3.1}{}}
\newlabel{fig:sigmoid_function}{{3b}{5}{sigmoid関数\relax }{subfigure.3.2}{}}
\newlabel{sub@fig:sigmoid_function}{{b}{5}{sigmoid関数\relax }{subfigure.3.2}{}}
\newlabel{fig:tanh_function}{{3c}{5}{tanh関数\relax }{subfigure.3.3}{}}
\newlabel{sub@fig:tanh_function}{{c}{5}{tanh関数\relax }{subfigure.3.3}{}}
\newlabel{fig:softplus_function}{{3d}{5}{softplus関数\relax }{subfigure.3.4}{}}
\newlabel{sub@fig:softplus_function}{{d}{5}{softplus関数\relax }{subfigure.3.4}{}}
\newlabel{fig:relu_function}{{3e}{5}{ReLU関数\relax }{subfigure.3.5}{}}
\newlabel{sub@fig:relu_function}{{e}{5}{ReLU関数\relax }{subfigure.3.5}{}}
\newlabel{fig:leaky_relu_function}{{3f}{5}{Leaky ReLU関数\relax }{subfigure.3.6}{}}
\newlabel{sub@fig:leaky_relu_function}{{f}{5}{Leaky ReLU関数\relax }{subfigure.3.6}{}}
\newlabel{fig:elu_function}{{3g}{5}{ELU関数\relax }{subfigure.3.7}{}}
\newlabel{sub@fig:elu_function}{{g}{5}{ELU関数\relax }{subfigure.3.7}{}}
\newlabel{fig:identity_function}{{3h}{5}{恒等関数\relax }{subfigure.3.8}{}}
\newlabel{sub@fig:identity_function}{{h}{5}{恒等関数\relax }{subfigure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 活性化関数のプロット\relax }}{5}{figure.3}}
\newlabel{fig:plot_of_activate_function}{{3}{6}{活性化関数のプロット\relax }{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}学習とは}{6}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}分類問題・回帰問題}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}分類問題の評価指標}{6}{subsection.6.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 混同行列\relax }}{7}{table.1}}
\newlabel{tab:confusion_matrix}{{1}{7}{混同行列\relax }{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}回帰問題の評価指標}{7}{subsection.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7}損失関数}{7}{section.7}}
\newlabel{sec:loss_function}{{7}{7}{損失関数}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}勾配降下法}{8}{section.8}}
\newlabel{sec:gradient_descent}{{8}{8}{勾配降下法}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}勾配降下法}{9}{subsection.8.1}}
\newlabel{eq:update_param}{{38}{9}{勾配降下法}{equation.8.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}学習率}{9}{subsection.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}確率的勾配降下法}{9}{subsection.8.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}ミニバッチ学習}{10}{subsection.8.4}}
\@writefile{toc}{\contentsline {section}{\numberline {9}誤差逆伝搬法}{10}{section.9}}
\newlabel{eq:def:delta}{{45}{10}{誤差逆伝搬法}{equation.9.45}{}}
\newlabel{eq:pdv_param}{{47}{10}{誤差逆伝搬法}{equation.9.47}{}}
\newlabel{eq:backprop_delta}{{50}{11}{誤差逆伝搬法}{equation.9.50}{}}
\newlabel{eq:delta}{{54}{11}{誤差逆伝搬法}{equation.9.54}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}最適化手法}{12}{section.10}}
\@writefile{toc}{\contentsline {section}{\numberline {11}重みの初期化}{12}{section.11}}
\@writefile{toc}{\contentsline {section}{\numberline {12}正則化}{13}{section.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}L2正則化}{14}{subsection.12.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Dropout}{14}{subsection.12.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Batch Normalization}{14}{subsection.12.3}}
\newlabel{LastPage}{{}{15}{}{page.15}{}}
\xdef\lastpage@lastpage{15}
\xdef\lastpage@lastpageHy{15}
