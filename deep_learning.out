\BOOKMARK [1][-]{section.1}{1 はじめに}{}% 1
\BOOKMARK [1][-]{section.2}{2 Perceptron}{}% 2
\BOOKMARK [1][-]{section.3}{3 Neural Network}{}% 3
\BOOKMARK [1][-]{section.4}{4 活性化関数}{}% 4
\BOOKMARK [1][-]{section.5}{5 学習とは}{}% 5
\BOOKMARK [1][-]{section.6}{6 分類問題・回帰問題}{}% 6
\BOOKMARK [2][-]{subsection.6.1}{6.1 分類問題の評価指標}{section.6}% 7
\BOOKMARK [2][-]{subsection.6.2}{6.2 回帰問題の評価指標}{section.6}% 8
\BOOKMARK [1][-]{section.7}{7 損失関数}{}% 9
\BOOKMARK [1][-]{section.8}{8 勾配降下法}{}% 10
\BOOKMARK [2][-]{subsection.8.1}{8.1 勾配降下法}{section.8}% 11
\BOOKMARK [2][-]{subsection.8.2}{8.2 学習率}{section.8}% 12
\BOOKMARK [2][-]{subsection.8.3}{8.3 確率的勾配降下法}{section.8}% 13
\BOOKMARK [2][-]{subsection.8.4}{8.4 ミニバッチ学習}{section.8}% 14
\BOOKMARK [1][-]{section.9}{9 誤差逆伝搬法}{}% 15
\BOOKMARK [1][-]{section.10}{10 最適化手法}{}% 16
\BOOKMARK [1][-]{section.11}{11 重みの初期化}{}% 17
\BOOKMARK [1][-]{section.12}{12 正則化}{}% 18
\BOOKMARK [2][-]{subsection.12.1}{12.1 L2正則化}{section.12}% 19
\BOOKMARK [2][-]{subsection.12.2}{12.2 Dropout}{section.12}% 20
\BOOKMARK [2][-]{subsection.12.3}{12.3 Batch Normalization}{section.12}% 21
